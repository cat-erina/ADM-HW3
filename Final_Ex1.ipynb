{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import itertools\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Get the list of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_page = 'https://raw.githubusercontent.com/CriMenghini/ADM/master/2019/Homework_3/data/movies1.html'\n",
    "big_page_response = requests.get(big_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_page_soup = BeautifulSoup(big_page_response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Crawl Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in big_page_soup.find_all('tr')[1:]:\n",
    "    url = i.find_all('a')[0].get(\"href\") # get the url in the second column of each row starting from the sec. row\n",
    "    page_response= requests.get(url)  # reponse to the request\n",
    "    \n",
    "    if page_response.status_code == 200:  # 200 == means everthing is ok\n",
    "        with open(os.path.join('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/html_files1',\"movie\"+str(counter+1)+\".html\"), \"w\") as file:\n",
    "            page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "            file.write(str(page_soup))  # writes the html page\n",
    "            List_url.append(url) # add url to the list L\n",
    "        counter += 1\n",
    "    elif page_response.status_code == 429: # 429 == means that your doing too many requaets\n",
    "        print('we must wait...')\n",
    "        time.sleep(600) # wait 10 mins \n",
    "        page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "        with open(os.path.join('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/html_files1',\"movie\"+str(counter+1)+\".html\"), \"w\") as file:\n",
    "            file.write(str(page_soup))  # writes the html page\n",
    "            List_url.append(url) # add url to the list L\n",
    "        counter += 1\n",
    "    elif counter%25==0:  # every 25 files, wait 10 seconds\n",
    "        time.sleep(10)\n",
    "        page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "        with open(os.path.join('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/html_files1',\"movie\"+str(counter+1)+\".html\"), \"w\") as file:\n",
    "            file.write(str(page_soup))  # writes the html page\n",
    "            List_url.append(url) # add url to the list L\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    print(\"parsed movie \" + str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/Downdloaded_url', 'w', newline=\"\") as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     wr.writerow(List_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "with open('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/Downdloaded_url', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lst.append(list(reader)[0])\n",
    "List_url = lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stop = set(stopwords.words('english'))\n",
    "Vocabulary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questo mi derve per pulire gli output dell'infobox\n",
    "def clean_col(string): \n",
    "    clean1 = string.strip('\\n') # remove all escape characters\n",
    "    pattern = r'\\[.*?\\]'  # remove all square brakets and content\n",
    "    clean2 = re.sub(pattern, '', clean1)\n",
    "    return(clean2)\n",
    "\n",
    "# questo per ricavare i dati dall'infobox\n",
    "def info_tsv(film_soup, movie_number, filename):\n",
    "    \n",
    "    pattern = r'\\[.*?\\]'  # remove all square brakets and content\n",
    "    \n",
    "    infb = ['Directed by', 'Produced by', 'Written by', 'Screenplay by',\n",
    "           'Story by', 'Based on', 'Starring', 'Narrated by', 'Music by',\n",
    "           'Cinematography', 'Edited by', 'Production company', \n",
    "            'Distributed by', 'Release date', 'Running time', 'Country',\n",
    "           'Language', 'Budget'] # lista degli elementi che vogliamo\n",
    "                                # ho aagiunto anche cose inutili sempre \n",
    "                                # per provare il codice\n",
    "    L = []  # Questa lista conterrÃ  tutti gli elementi trovati nell'infob.\n",
    "            # e quelli mancanti. \n",
    "        \n",
    "    # Retrieve the Title   \n",
    "        \n",
    "    Initial_Title = film_soup.select(\"#firstHeading\")[0].text\n",
    "    L.append(['Title', str(Initial_Title)])\n",
    "    \n",
    "    \n",
    "    # Retrieve the Intro\n",
    "    Intro2 = []\n",
    "    Intro3 = []  # don't remove duplicates\n",
    "    \n",
    "    contents = film_soup.findAll('div', attrs={'id': 'toc'}) \n",
    "    if len(contents) > 0:\n",
    "        Intr = contents[0].fetchPreviousSiblings('p')\n",
    "        Intro = []\n",
    "        if len(Intr) > 0:\n",
    "            for p in reversed(Intr):\n",
    "                if len(p.text) > 5:\n",
    "                    Intro.append(p.text)\n",
    "                else:\n",
    "                    continue\n",
    "            Intro = ''.join(Intro)\n",
    "            Final_intro = re.sub(pattern, '', Intro)\n",
    "            \n",
    "            if len(Final_intro)>20:\n",
    "                for small_word in Final_intro.split():\n",
    "                    row_cl = small_word.strip()  #  strips all kinds of trailing whitespace by default\n",
    "                    row_cl_noPunct = re.sub(r'[^\\w\\s]','',row_cl) # remove puntuation\n",
    "                    clean_row = [i for i in row_cl_noPunct.lower().split() if i not in stop] #remove stopwords\n",
    "\n",
    "                    #if after cleaning you reamin with  noting append an empty string\n",
    "                    if clean_row is None or len(clean_row) == 0:\n",
    "                            Intro2.append('')\n",
    "\n",
    "                    # if after cleaning there are still some useful/important words, append them\n",
    "                    else:\n",
    "                        for word in clean_row:\n",
    "                            Intro2.append(ps.stem(word))\n",
    "                    Intro3 = Intro2\n",
    "                    Intro2 = list(set(Intro2))\n",
    "                L.append(['Intro', Final_intro.strip()])\n",
    "            else:\n",
    "                L.append(['Intro', 'NA'])\n",
    "    \n",
    "    \n",
    "    # Retrieve the Plot\n",
    "    \n",
    "    plot = []\n",
    "    FFinal_plot = []\n",
    "    FFinal_plot2 = []   # don't remove duplicates\n",
    "    possibles = ['Plot','Synopsis','Plot synopsis','Plot summary', \n",
    "                 'Story','Plotline','The Beginning','Summary',\n",
    "                'Content','Premise', 'Intro', 'Intro']\n",
    "    for i in possibles:\n",
    "        # find the node with id of \"Plot\"\n",
    "        items = film_soup.find(id=i)\n",
    "        if items is None or len(items) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # walk through the siblings of the parent (H2) node \n",
    "            # until we reach the next H2 node\n",
    "            for element in items.parent.nextSiblingGenerator():\n",
    "                if element.name == \"h2\":\n",
    "                    break\n",
    "                if hasattr(element, \"text\"):\n",
    "                    plot.append(element.text)\n",
    "    plot = \"\".join(plot)\n",
    "    # remove all square brakets and content\n",
    "    Final_plot = re.sub(pattern, '', plot)\n",
    "    if len(Final_plot) > 20:\n",
    "        for small_word in Final_plot.split():\n",
    "            row_cl = Final_plot.strip()  #  strips all kinds of trailing whitespace by default\n",
    "            row_cl_noPunct = re.sub(r'[^\\w\\s]','',row_cl) # remove puntuation\n",
    "            clean_row = [i for i in row_cl_noPunct.lower().split() if i not in stop] #remove stopwords\n",
    "\n",
    "            #if after cleaning you reamin with  noting append an empty string\n",
    "            if clean_row is None or len(clean_row) == 0:\n",
    "                    FFinal_plot.append('')\n",
    "\n",
    "            # if after cleaning there are still some useful/important words, append them\n",
    "            else:\n",
    "                for word in clean_row:\n",
    "                    FFinal_plot.append(ps.stem(word))\n",
    "                FFinal_plot2 = FFinal_plot\n",
    "                FFinal_plot = list(set(FFinal_plot))\n",
    "        L.append(['Plot', Final_plot.strip()])\n",
    "    else:\n",
    "        L.append(['Plot', 'NA'])\n",
    "        \n",
    "    # merge plot anf Intro to create dict\n",
    "    \n",
    "    merged2 = Intro3+FFinal_plot\n",
    "    \n",
    "    \n",
    "    L.append(['Merged', merged2])\n",
    "    \n",
    "    merged = list(set(FFinal_plot + Intro2))\n",
    "    page_name = filename.replace(\"html\", \"tsv\") # without extension\n",
    "    for i in merged:\n",
    "        if i not in Vocabulary.keys():\n",
    "            Vocabulary[i] = [page_name]\n",
    "        elif page_name not in Vocabulary[i]:\n",
    "            Vocabulary[i].append(page_name)\n",
    "    \n",
    "    # Retrieve info in the infobox\n",
    "        \n",
    "    if len(film_soup.findAll('table', {'class': 'infobox vevent'}))>0:\n",
    "        if len(film_soup.findAll('table', {'class': 'infobox vevent'})[0].tbody.findAll('tr'))>0:\n",
    "            Title = film_soup.findAll('table', {'class': 'infobox vevent'})[0].tbody.findAll('tr')[0].text\n",
    "            if len(Title)>75:\n",
    "                \n",
    "                L.append(['Name', 'NA'])\n",
    "            else:\n",
    "                L.append(['Name', Title]) # mi ricavo il titolo dall'infobox\n",
    "            \n",
    "        else:\n",
    "            L.append(['Name', 'NA'])\n",
    "            \n",
    "    in_table = [] # mi savo gli elementi dell'infobox qui\n",
    "    \n",
    "    if len(film_soup.findAll('table', {'class': 'infobox vevent'}))>0:\n",
    "        if len(film_soup.findAll('table', {'class': 'infobox vevent'})[0].tbody.findAll('tr'))>0:\n",
    "            for row in film_soup.findAll('table', {'class': 'infobox vevent'})[0].tbody.findAll('tr')[1:]:\n",
    "                first_col = row.findAll('th') # first column of infobox\n",
    "                if len(first_col)>0:\n",
    "                    second_col = row.findAll('td')\n",
    "                    if len(second_col)>0:\n",
    "                        second_col = row.findAll('td')[0].text # second column of info\n",
    "                        new_second_col = clean_col(second_col) # clean the output\n",
    "\n",
    "                        in_table.append(first_col[0].text) \n",
    "                        in_table.append(new_second_col)\n",
    "                        \n",
    "\n",
    "            # put NA to all missing values\n",
    "            for i in infb:\n",
    "                if i in in_table:\n",
    "                    index = in_table.index(i)\n",
    "                    L.append([i, in_table[index +1]])\n",
    "                else:\n",
    "                    L.append([i, 'NA']) \n",
    "    L.append(['Url', List_url[int(movie_number) -1]])\n",
    "    return(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Title', 'One Summer Love'],\n",
       " ['Intro',\n",
       "  'One Summer Love, originally titled Dragonfly, is a 1976 romantic drama film directed by Gilbert Cates from a screenplay by N. Richard Nash. It stars Beau Bridges and Susan Sarandon and features Mildred Dunnock and Ann Wedgeworth.'],\n",
       " ['Plot',\n",
       "  'After being released from a mental hospital, Jesse (Bridges) sets out to find and rejoin his off-beat family. While doing so, he meets a pretty young woman named Chloe (Sarandon) who works in a movie theatre, and they fall in love, which resolves his psychological problems.'],\n",
       " ['Merged',\n",
       "  ['',\n",
       "   'one',\n",
       "   'direct',\n",
       "   'susan',\n",
       "   'romant',\n",
       "   'love',\n",
       "   'bridg',\n",
       "   'drama',\n",
       "   'film',\n",
       "   'dragonfli',\n",
       "   'richard',\n",
       "   'beau',\n",
       "   'cate',\n",
       "   'titl',\n",
       "   'mildr',\n",
       "   'summer',\n",
       "   '1976',\n",
       "   'dunnock',\n",
       "   'screenplay',\n",
       "   'gilbert',\n",
       "   'ann',\n",
       "   'n',\n",
       "   'star',\n",
       "   'nash',\n",
       "   'origin',\n",
       "   'sarandon',\n",
       "   'featur',\n",
       "   'wedgeworth',\n",
       "   'theatr',\n",
       "   'meet',\n",
       "   'jess',\n",
       "   'releas',\n",
       "   'love',\n",
       "   'name',\n",
       "   'bridg',\n",
       "   'offbeat',\n",
       "   'woman',\n",
       "   'chloe',\n",
       "   'pretti',\n",
       "   'movi',\n",
       "   'fall',\n",
       "   'mental',\n",
       "   'set',\n",
       "   'rejoin',\n",
       "   'hospit',\n",
       "   'work',\n",
       "   'young',\n",
       "   'resolv',\n",
       "   'famili',\n",
       "   'find',\n",
       "   'sarandon',\n",
       "   'problem',\n",
       "   'psycholog']],\n",
       " ['Name', 'One Summer Love'],\n",
       " ['Directed by', 'Gilbert Cates'],\n",
       " ['Produced by', 'Gilbert Cates'],\n",
       " ['Written by', 'N. Richard Nash'],\n",
       " ['Screenplay by', 'NA'],\n",
       " ['Story by', 'NA'],\n",
       " ['Based on', 'NA'],\n",
       " ['Starring', 'Beau BridgesSusan Sarandon'],\n",
       " ['Narrated by', 'NA'],\n",
       " ['Music by', 'Stephen Lawrence'],\n",
       " ['Cinematography', 'Gerald Hirschfeld'],\n",
       " ['Edited by', 'Barry Malkin'],\n",
       " ['Production company', 'NA'],\n",
       " ['Distributed by', 'American International Pictures'],\n",
       " ['Release date', '1976'],\n",
       " ['Running time', '98 minutes'],\n",
       " ['Country', 'United States'],\n",
       " ['Language', 'English'],\n",
       " ['Budget', 'NA'],\n",
       " ['Url', 'https://en.wikipedia.org/wiki/Alice_in_Wonderland_(1903_film)']]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST CODE\n",
    "\n",
    "page = open(\"/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/html_files/movie9245.html\", \"r\")\n",
    "page = page.read()\n",
    "f =  BeautifulSoup(page)\n",
    "\n",
    "t = info_tsv(f,5, 'movie9245')\n",
    "with open('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/tsv_files/'+ 'movie9245' +'.tsv', 'wt') as out_file:\n",
    "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "        for col in info_tsv(f,5, 'movie9245'):\n",
    "                tsv_writer.writerow([col[0], col[1]])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_done = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsv created 1\n",
      "tsv created 2\n",
      "tsv created 3\n",
      "tsv created 4\n",
      "tsv created 5\n",
      "tsv created 6\n",
      "tsv created 7\n",
      "tsv created 8\n",
      "tsv created 9\n",
      "tsv created 10\n",
      "tsv created 11\n",
      "tsv created 12\n",
      "tsv created 13\n",
      "tsv created 14\n",
      "tsv created 15\n",
      "tsv created 16\n",
      "tsv created 17\n",
      "tsv created 18\n",
      "tsv created 19\n",
      "tsv created 20\n",
      "tsv created 21\n",
      "tsv created 22\n",
      "tsv created 23\n",
      "tsv created 24\n",
      "tsv created 25\n",
      "tsv created 26\n",
      "tsv created 27\n",
      "tsv created 28\n",
      "tsv created 29\n",
      "tsv created 30\n",
      "tsv created 31\n",
      "tsv created 32\n",
      "tsv created 33\n",
      "tsv created 34\n",
      "tsv created 35\n",
      "tsv created 36\n",
      "tsv created 37\n",
      "tsv created 38\n",
      "tsv created 39\n",
      "tsv created 40\n",
      "tsv created 41\n",
      "tsv created 42\n",
      "tsv created 43\n",
      "tsv created 44\n",
      "tsv created 45\n",
      "tsv created 46\n",
      "tsv created 47\n",
      "tsv created 48\n",
      "tsv created 49\n",
      "tsv created 50\n",
      "tsv created 51\n",
      "tsv created 52\n",
      "tsv created 53\n",
      "tsv created 54\n",
      "tsv created 55\n",
      "tsv created 56\n",
      "tsv created 57\n",
      "tsv created 58\n",
      "tsv created 59\n",
      "tsv created 60\n",
      "tsv created 61\n",
      "tsv created 62\n",
      "tsv created 63\n",
      "tsv created 64\n",
      "tsv created 65\n",
      "tsv created 66\n",
      "tsv created 67\n",
      "tsv created 68\n",
      "tsv created 69\n",
      "tsv created 70\n",
      "tsv created 71\n",
      "tsv created 72\n",
      "tsv created 73\n",
      "tsv created 74\n",
      "tsv created 75\n",
      "tsv created 76\n",
      "tsv created 77\n",
      "tsv created 78\n",
      "tsv created 79\n",
      "tsv created 80\n",
      "tsv created 81\n",
      "tsv created 82\n",
      "tsv created 83\n",
      "tsv created 84\n",
      "tsv created 85\n",
      "tsv created 86\n",
      "tsv created 87\n",
      "tsv created 88\n",
      "tsv created 89\n",
      "tsv created 90\n",
      "tsv created 91\n",
      "tsv created 92\n",
      "tsv created 93\n",
      "tsv created 94\n",
      "tsv created 95\n",
      "tsv created 96\n",
      "tsv created 97\n",
      "tsv created 98\n",
      "tsv created 99\n",
      "tsv created 100\n",
      "tsv created 101\n",
      "tsv created 102\n",
      "tsv created 103\n",
      "tsv created 104\n",
      "tsv created 105\n",
      "tsv created 106\n",
      "tsv created 107\n",
      "tsv created 108\n",
      "tsv created 109\n",
      "tsv created 110\n",
      "tsv created 111\n",
      "tsv created 112\n",
      "tsv created 113\n",
      "tsv created 114\n",
      "tsv created 115\n",
      "tsv created 116\n",
      "tsv created 117\n",
      "tsv created 118\n",
      "tsv created 119\n",
      "tsv created 120\n",
      "tsv created 121\n",
      "tsv created 122\n",
      "tsv created 123\n",
      "tsv created 124\n",
      "tsv created 125\n",
      "tsv created 126\n",
      "tsv created 127\n",
      "tsv created 128\n",
      "tsv created 129\n",
      "tsv created 130\n",
      "tsv created 131\n",
      "tsv created 132\n",
      "tsv created 133\n",
      "tsv created 134\n",
      "tsv created 135\n",
      "tsv created 136\n",
      "tsv created 137\n",
      "tsv created 138\n",
      "tsv created 139\n",
      "tsv created 140\n",
      "tsv created 141\n",
      "tsv created 142\n",
      "tsv created 143\n",
      "tsv created 144\n",
      "tsv created 145\n",
      "tsv created 146\n",
      "tsv created 147\n",
      "tsv created 148\n",
      "tsv created 149\n",
      "tsv created 150\n",
      "tsv created 151\n",
      "tsv created 152\n",
      "tsv created 153\n",
      "tsv created 154\n",
      "tsv created 155\n",
      "tsv created 156\n",
      "tsv created 157\n",
      "tsv created 158\n",
      "tsv created 159\n",
      "tsv created 160\n",
      "tsv created 161\n",
      "tsv created 162\n",
      "tsv created 163\n",
      "tsv created 164\n",
      "tsv created 165\n",
      "tsv created 166\n",
      "tsv created 167\n",
      "tsv created 168\n",
      "tsv created 169\n",
      "tsv created 170\n",
      "tsv created 171\n",
      "tsv created 172\n",
      "tsv created 173\n",
      "tsv created 174\n",
      "tsv created 175\n",
      "tsv created 176\n",
      "tsv created 177\n",
      "tsv created 178\n",
      "tsv created 179\n",
      "tsv created 180\n",
      "tsv created 181\n",
      "tsv created 182\n",
      "tsv created 183\n",
      "tsv created 184\n",
      "tsv created 185\n",
      "tsv created 186\n",
      "tsv created 187\n",
      "tsv created 188\n",
      "tsv created 189\n",
      "tsv created 190\n",
      "tsv created 191\n",
      "tsv created 192\n",
      "tsv created 193\n",
      "tsv created 194\n",
      "tsv created 195\n",
      "tsv created 196\n",
      "tsv created 197\n",
      "tsv created 198\n",
      "tsv created 199\n",
      "tsv created 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-9498d643d7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/tsv_files/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpage_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mtsv_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0minfo_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovie_number\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-d62eeeabd72b>\u001b[0m in \u001b[0;36minfo_tsv\u001b[0;34m(film_soup, movie_number, filename)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# find the node with id of \"Plot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilm_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, name, attrs, recursive, text, **kwargs)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         criteria.\"\"\"\n\u001b[1;32m   1281\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[0;31m# BS3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0mfindChildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m  \u001b[0;31m# BS2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m         \u001b[0;31m# If it's text, make sure the text matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch_tag\u001b[0;34m(self, markup_name, markup_attrs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                                 \u001b[0mmarkup_attr_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mattr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup_attr_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m                         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   1528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmarkup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_against\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths = '/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/html_files/'\n",
    "\n",
    "    \n",
    "for filename in os.listdir(paths):\n",
    "    if filename not in movies_done:\n",
    "        if filename.endswith(\".html\"):\n",
    "            ff = open(paths + filename, 'r')\n",
    "            html = ff.read()\n",
    "            film = BeautifulSoup(html)\n",
    "\n",
    "            page_name = filename.rstrip('.html') # without extension\n",
    "            movies_done.append(filename)\n",
    "            \n",
    "            movie_number = re.findall('\\d+', filename )\n",
    "            movie_number = movie_number[0]\n",
    "            \n",
    "            with open('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/tsv_files/'+page_name+'.tsv', 'wt') as out_file:\n",
    "                tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "                if info_tsv(film,movie_number , filename) is None or len(info_tsv(film, movie_number, filename)) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    for col in info_tsv(film, movie_number, filename):\n",
    "                        tsv_writer.writerow([col[0], col[1]])\n",
    "            print('tsv created '+ str(len(movies_done)))\n",
    "\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "print('DONE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yves/Desktop/Data_Science/first_year/first_semester/adm/adm_hw3/Vocabulary.json', 'w') as outfile:\n",
    "    json.dump(Vocabulary, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
